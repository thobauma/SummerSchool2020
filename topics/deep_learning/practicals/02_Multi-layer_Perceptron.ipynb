{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A python implementation for the MLP\n",
    "MLP code based on [Marsland (2014)](https://seat.massey.ac.nz/personal/s.r.marsland/MLbook.html)\n",
    "\n",
    "Contains:\n",
    "* 1. a perceptron class called **pcn**\n",
    "* 2. a Multi-layer perceptron class called **mlp**\n",
    "* 3. a test-case of the pcn\n",
    "* 4. a test-case of mlp classification\n",
    "* 5. an analytical testcase for mlp regression\n",
    "* 6. classification with the Iris data set\n",
    "* 7. classification with the MNIST data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron class (PCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class pcn:\n",
    "    \"\"\" A basic Perceptron\"\"\"\n",
    "    def __init__(self,inputs,targets):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        if np.ndim(inputs)>1:\n",
    "            self.nIn = np.shape(inputs)[1]\n",
    "        else: \n",
    "            self.nIn = 1\n",
    "\n",
    "        if np.ndim(targets)>1:\n",
    "            self.nOut = np.shape(targets)[1]\n",
    "        else:\n",
    "            self.nOut = 1\n",
    "\n",
    "        self.nData = np.shape(inputs)[0]\n",
    "\n",
    "        # Initialise network\n",
    "        self.weights = np.random.rand(self.nIn+1,self.nOut)*0.1-0.05\n",
    "\n",
    "    def pcntrain(self,inputs,targets,eta,nIterations):\n",
    "        \"\"\" Train the thing \"\"\"\t\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)\n",
    "        # Training\n",
    "        change = range(self.nData)\n",
    "\n",
    "        for n in range(nIterations):\n",
    "            self.activations = self.pcnfwd(inputs);\n",
    "            self.weights -= eta*np.dot(np.transpose(inputs),self.activations-targets)\n",
    "            \n",
    "            #Randomise order of inputs\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "\n",
    "        #return self.weights\n",
    "\n",
    "    def pcnfwd(self,inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "        # Compute activations\n",
    "        activations =  np.dot(inputs,self.weights)\n",
    "\n",
    "        # Threshold the activations\n",
    "        return np.where(activations>0,1,0)\n",
    "\n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)\n",
    "\n",
    "        outputs = np.dot(inputs,self.weights)\n",
    "\n",
    "        nClasses = np.shape(targets)[1]\n",
    "\n",
    "        if nClasses==1:\n",
    "            nClasses = 2\n",
    "            outputs = np.where(outputs>0,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nClasses,nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "\n",
    "        print(cm)\n",
    "        print(np.trace(cm)/np.sum(cm))\n",
    "\n",
    "def logic():\n",
    "    import pcn\n",
    "    \"\"\" Run AND and XOR logic functions\"\"\"\n",
    "\n",
    "    a = np.array([[0,0,0],[0,1,0],[1,0,0],[1,1,1]])\n",
    "    b = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "\n",
    "    p = pcn.pcn(a[:,0:2],a[:,2:])\n",
    "    p.pcntrain(a[:,0:2],a[:,2:],0.25,10)\n",
    "    p.confmat(a[:,0:2],a[:,2:])\n",
    "\n",
    "    q = pcn.pcn(b[:,0:2],b[:,2:])\n",
    "    q.pcntrain(b[:,0:2],b[:,2:],0.25,10)\n",
    "    q.confmat(b[:,0:2],b[:,2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-layer Perceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    \"\"\" A Multi-Layer Perceptron\"\"\"\n",
    "    \n",
    "    def __init__(self,inputs,targets,nhidden,beta=1,momentum=0.9,outtype='logistic'):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nhidden = nhidden\n",
    "\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.outtype = outtype\n",
    "    \n",
    "        # Initialise network\n",
    "        self.weights1 = (np.random.rand(self.nin+1,self.nhidden)-0.5)*2/np.sqrt(self.nin)\n",
    "        self.weights2 = (np.random.rand(self.nhidden+1,self.nout)-0.5)*2/np.sqrt(self.nhidden)\n",
    "\n",
    "    def earlystopping(self,inputs,targets,valid,validtargets,eta,niterations=100):\n",
    "    \n",
    "        valid = np.concatenate((valid,-np.ones((np.shape(valid)[0],1))),axis=1)\n",
    "        \n",
    "        old_val_error1 = 100002\n",
    "        old_val_error2 = 100001\n",
    "        new_val_error = 100000\n",
    "        \n",
    "        count = 0\n",
    "        while (((old_val_error1 - new_val_error) > 0.001) or ((old_val_error2 - old_val_error1)>0.001)):\n",
    "            count+=1\n",
    "            print(count)\n",
    "            self.mlptrain(inputs,targets,eta,niterations)\n",
    "            old_val_error2 = old_val_error1\n",
    "            old_val_error1 = new_val_error\n",
    "            validout = self.mlpfwd(valid)\n",
    "            new_val_error = 0.5*np.sum((validtargets-validout)**2)\n",
    "            \n",
    "        print(\"Stopped\", new_val_error,old_val_error1, old_val_error2)\n",
    "        return new_val_error\n",
    "    \n",
    "    def mlptrain(self,inputs,targets,eta,niterations):\n",
    "        \"\"\" Train the thing \"\"\"    \n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.ndata,1))),axis=1)\n",
    "        change = range(self.ndata)\n",
    "    \n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "            \n",
    "        for n in range(niterations):\n",
    "    \n",
    "            self.outputs = self.mlpfwd(inputs)\n",
    "\n",
    "            error = 0.5*np.sum((self.outputs-targets)**2)\n",
    "            if (np.mod(n,100)==0):\n",
    "                print(\"Iteration: \",n, \" Error: \",error)    \n",
    "\n",
    "            # Different types of output neurons\n",
    "            if self.outtype == 'linear':\n",
    "            \tdeltao = (self.outputs-targets)/self.ndata\n",
    "            elif self.outtype == 'logistic':\n",
    "            \tdeltao = self.beta*(self.outputs-targets)*self.outputs*(1.0-self.outputs)\n",
    "            elif self.outtype == 'softmax':\n",
    "                deltao = (self.outputs-targets)*(self.outputs*(-self.outputs)+self.outputs)/self.ndata \n",
    "            else:\n",
    "            \tprint(\"error\")\n",
    "            \n",
    "            deltah = self.hidden*self.beta*(1.0-self.hidden)*(np.dot(deltao,np.transpose(self.weights2)))\n",
    "                      \n",
    "            updatew1 = eta*(np.dot(np.transpose(inputs),deltah[:,:-1])) + self.momentum*updatew1\n",
    "            updatew2 = eta*(np.dot(np.transpose(self.hidden),deltao)) + self.momentum*updatew2\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "                \n",
    "            # Randomise order of inputs (not necessary for matrix-based calculation)\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "            \n",
    "    def mlpfwd(self,inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "\n",
    "        self.hidden = np.dot(inputs,self.weights1);\n",
    "        self.hidden = 1.0/(1.0+np.exp(-self.beta*self.hidden))\n",
    "        self.hidden = np.concatenate((self.hidden,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "\n",
    "        outputs = np.dot(self.hidden,self.weights2);\n",
    "\n",
    "        # Different types of output neurons\n",
    "        if self.outtype == 'linear':\n",
    "        \treturn outputs\n",
    "        elif self.outtype == 'logistic':\n",
    "            return 1.0/(1.0+np.exp(-self.beta*outputs))\n",
    "        elif self.outtype == 'softmax':\n",
    "            normalisers = np.sum(np.exp(outputs),axis=1)*np.ones((1,np.shape(outputs)[0]))\n",
    "            return np.transpose(np.transpose(np.exp(outputs))/normalisers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "        outputs = self.mlpfwd(inputs)\n",
    "        \n",
    "        nclasses = np.shape(targets)[1]\n",
    "\n",
    "        if nclasses==1:\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs>0.5,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nclasses,nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "\n",
    "        print(\"Confusion matrix is:\")\n",
    "        print(cm)\n",
    "        print(\"Percentage Correct: \",np.trace(cm)/np.sum(cm)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the perceptron with the simple OR data-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 3.]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pcn\n",
    "\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "targets = np.array([[0],[1],[1],[1]])\n",
    "p = pcn.pcn(inputs,targets)\n",
    "p.pcntrain(inputs,targets,0.25,6)\n",
    "p.confmat(inputs,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the MLP with logical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  0.6618159664923471\n",
      "Iteration:  100  Error:  0.036086772698034134\n",
      "Iteration:  200  Error:  0.005904418340716359\n",
      "Iteration:  300  Error:  0.003101659310278744\n",
      "Iteration:  400  Error:  0.002073041089272464\n",
      "Iteration:  500  Error:  0.0015455039974929217\n",
      "Iteration:  600  Error:  0.0012267480155394254\n",
      "Iteration:  700  Error:  0.0010141724128340756\n",
      "Iteration:  800  Error:  0.000862709842149745\n",
      "Iteration:  900  Error:  0.000749537186384387\n",
      "Iteration:  1000  Error:  0.0006618900743824764\n",
      "Confusion matrix is:\n",
      "[[3. 0.]\n",
      " [0. 1.]]\n",
      "Percentage Correct:  100.0\n",
      "Iteration:  0  Error:  0.5284622827244535\n",
      "Iteration:  100  Error:  0.4999815109186363\n",
      "Iteration:  200  Error:  0.4998525988276532\n",
      "Iteration:  300  Error:  0.49885050871017284\n",
      "Iteration:  400  Error:  0.4333613423669407\n",
      "Iteration:  500  Error:  0.02261114482925698\n",
      "Iteration:  600  Error:  0.007540990729356722\n",
      "Iteration:  700  Error:  0.004480061021622528\n",
      "Iteration:  800  Error:  0.0031656638185134896\n",
      "Iteration:  900  Error:  0.002438936930390839\n",
      "Iteration:  1000  Error:  0.001979339655473407\n",
      "Iteration:  1100  Error:  0.001663146645153137\n",
      "Iteration:  1200  Error:  0.0014326451523058257\n",
      "Iteration:  1300  Error:  0.0012573477228123805\n",
      "Iteration:  1400  Error:  0.0011196557253057794\n",
      "Iteration:  1500  Error:  0.0010087104660327299\n",
      "Iteration:  1600  Error:  0.0009174541588458499\n",
      "Iteration:  1700  Error:  0.0008411037168741077\n",
      "Iteration:  1800  Error:  0.000776304399156597\n",
      "Iteration:  1900  Error:  0.0007206347029906714\n",
      "Iteration:  2000  Error:  0.0006723035849408142\n",
      "Iteration:  2100  Error:  0.000629958224984818\n",
      "Iteration:  2200  Error:  0.0005925579927014601\n",
      "Iteration:  2300  Error:  0.000559289485973899\n",
      "Iteration:  2400  Error:  0.0005295078459250057\n",
      "Iteration:  2500  Error:  0.0005026953411109931\n",
      "Iteration:  2600  Error:  0.0004784315751990495\n",
      "Iteration:  2700  Error:  0.0004563716861133806\n",
      "Iteration:  2800  Error:  0.0004362301452788212\n",
      "Iteration:  2900  Error:  0.000417768549272445\n",
      "Iteration:  3000  Error:  0.00040078630248749825\n",
      "Iteration:  3100  Error:  0.00038511342323450655\n",
      "Iteration:  3200  Error:  0.00037060492992246603\n",
      "Iteration:  3300  Error:  0.0003571364171369403\n",
      "Iteration:  3400  Error:  0.0003446005377107875\n",
      "Iteration:  3500  Error:  0.00033290418168676776\n",
      "Iteration:  3600  Error:  0.00032196619642243276\n",
      "Iteration:  3700  Error:  0.00031171553060754337\n",
      "Iteration:  3800  Error:  0.0003020897130942973\n",
      "Iteration:  3900  Error:  0.00029303359820304206\n",
      "Iteration:  4000  Error:  0.0002844983246425753\n",
      "Iteration:  4100  Error:  0.00027644044682890436\n",
      "Iteration:  4200  Error:  0.00026882120622393103\n",
      "Iteration:  4300  Error:  0.00026160591707840696\n",
      "Iteration:  4400  Error:  0.00025476344617866755\n",
      "Iteration:  4500  Error:  0.000248265770247643\n",
      "Iteration:  4600  Error:  0.0002420875978191728\n",
      "Iteration:  4700  Error:  0.00023620604489903372\n",
      "Iteration:  4800  Error:  0.00023060035570222017\n",
      "Iteration:  4900  Error:  0.00022525166133032372\n",
      "Iteration:  5000  Error:  0.00022014277051455973\n",
      "Confusion matrix is:\n",
      "[[2. 0.]\n",
      " [0. 2.]]\n",
      "Percentage Correct:  100.0\n"
     ]
    }
   ],
   "source": [
    "import mlp\n",
    "\n",
    "anddata = np.array([[0,0,0],[0,1,0],[1,0,0],[1,1,1]])\n",
    "xordata = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "\n",
    "p = mlp.mlp(anddata[:,0:2],anddata[:,2:3],2)\n",
    "p.mlptrain(anddata[:,0:2],anddata[:,2:3],0.25,1001)\n",
    "p.confmat(anddata[:,0:2],anddata[:,2:3])\n",
    "\n",
    "q = mlp.mlp(xordata[:,0:2],xordata[:,2:3],2,outtype='logistic')\n",
    "q.mlptrain(xordata[:,0:2],xordata[:,2:3],0.25,5001)\n",
    "q.confmat(xordata[:,0:2],xordata[:,2:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first thing that we can do is check that this MLP can indeed learn the logic functions, especially the XOR. \n",
    "\n",
    "* There are a few things to notice about this. \n",
    "\n",
    "\n",
    "* One is that it does work, producing the correct answers, but the other is that even for the AND we need significantly more iterations than we did for the Perceptron. \n",
    "\n",
    "* So the benefits of a more complex network come at a cost, because it takes substantially more computational time to fit those weights to solve the problem, even for linear examples. \n",
    "\n",
    "* Sometimes, even 5000 iterations are not enough for the XOR function, and more have to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A simple regression problem\n",
    "\n",
    "* The regression problem we will look at is a very simple one. \n",
    "\n",
    "* We will take a set of samples generated by a simple mathematical function, and try to learn the generating function (that describes how the data was made) so that we can find the values of any inputs, not just the ones we have training data for.\n",
    "\n",
    "* The function that we will use is a very simple one, just a bit of a sine wave. \n",
    "\n",
    "* Before getting started, we need to normalize the data separate the data into training, testing, validation sets. \n",
    "\n",
    "* For this example there are only 40 data points \n",
    "\n",
    "* We use half of them as the training set, although that isn’t very many and might not be enough for the algorithm to learn effectively. \n",
    "\n",
    "* We can split the data in the ratio 50:25:25 by using the odd-numbered elements as training data, the even-numbered ones that do not divide by 4 for testing, and the rest for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  14.437878302676902\n",
      "Iteration:  100  Error:  6.8148976595570465\n",
      "1\n",
      "Iteration:  0  Error:  6.813421632448891\n",
      "2\n",
      "Iteration:  0  Error:  6.541211827213872\n",
      "3\n",
      "Iteration:  0  Error:  5.34358329205848\n",
      "4\n",
      "Iteration:  0  Error:  2.0209104443773884\n",
      "5\n",
      "Iteration:  0  Error:  1.550299557646615\n",
      "6\n",
      "Iteration:  0  Error:  1.5055229676770758\n",
      "7\n",
      "Iteration:  0  Error:  1.4910363523943921\n",
      "8\n",
      "Iteration:  0  Error:  1.4790768345734988\n",
      "9\n",
      "Iteration:  0  Error:  1.4654764135339695\n",
      "10\n",
      "Iteration:  0  Error:  1.4483080422671784\n",
      "11\n",
      "Iteration:  0  Error:  1.4250046462781791\n",
      "12\n",
      "Iteration:  0  Error:  1.3908198927490065\n",
      "13\n",
      "Iteration:  0  Error:  1.3360807256621505\n",
      "14\n",
      "Iteration:  0  Error:  1.2440869405074193\n",
      "15\n",
      "Iteration:  0  Error:  1.1060517114813613\n",
      "16\n",
      "Iteration:  0  Error:  0.9542063743880459\n",
      "17\n",
      "Iteration:  0  Error:  0.8365044272608969\n",
      "18\n",
      "Iteration:  0  Error:  0.760240623515487\n",
      "19\n",
      "Iteration:  0  Error:  0.7101517395434356\n",
      "20\n",
      "Iteration:  0  Error:  0.6746984674655385\n",
      "21\n",
      "Iteration:  0  Error:  0.647711598198839\n",
      "22\n",
      "Iteration:  0  Error:  0.6257111565766248\n",
      "23\n",
      "Iteration:  0  Error:  0.6065633585813781\n",
      "24\n",
      "Iteration:  0  Error:  0.5889451060366812\n",
      "25\n",
      "Iteration:  0  Error:  0.5721879440097721\n",
      "26\n",
      "Iteration:  0  Error:  0.5562271155580282\n",
      "27\n",
      "Iteration:  0  Error:  0.5413008115991439\n",
      "28\n",
      "Iteration:  0  Error:  0.5275249673308112\n",
      "29\n",
      "Iteration:  0  Error:  0.514855855710624\n",
      "30\n",
      "Iteration:  0  Error:  0.5032225804382612\n",
      "31\n",
      "Iteration:  0  Error:  0.4925578538161721\n",
      "32\n",
      "Iteration:  0  Error:  0.4827944372963597\n",
      "33\n",
      "Iteration:  0  Error:  0.473865031353268\n",
      "34\n",
      "Iteration:  0  Error:  0.4657036295203718\n",
      "35\n",
      "Iteration:  0  Error:  0.4582466322044212\n",
      "36\n",
      "Iteration:  0  Error:  0.45143358632755254\n",
      "37\n",
      "Iteration:  0  Error:  0.4452076401184612\n",
      "38\n",
      "Iteration:  0  Error:  0.4395157887411533\n",
      "39\n",
      "Iteration:  0  Error:  0.4343089641373241\n",
      "40\n",
      "Iteration:  0  Error:  0.4295420090745633\n",
      "41\n",
      "Iteration:  0  Error:  0.42517356704960546\n",
      "42\n",
      "Iteration:  0  Error:  0.42116591356632016\n",
      "43\n",
      "Iteration:  0  Error:  0.417484749231345\n",
      "44\n",
      "Iteration:  0  Error:  0.4140989707219112\n",
      "45\n",
      "Iteration:  0  Error:  0.4109804319002091\n",
      "46\n",
      "Iteration:  0  Error:  0.40810370416486896\n",
      "47\n",
      "Iteration:  0  Error:  0.4054458425207621\n",
      "Stopped 0.18173513997598373 0.18258568482277177 0.183516175697587\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe53b62d080>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the data\n",
    "import pylab as pl\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "x = np.linspace(0,1,40).reshape((40,1))\n",
    "t = np.sin(2*np.pi*x) + np.cos(4*np.pi*x) + np.random.randn(40).reshape((40,1))*0.2\n",
    "x = (x-0.5)*2\n",
    "\n",
    "# Split into training, testing, and validation sets\n",
    "train = x[0::2,:]\n",
    "test = x[1::4,:]\n",
    "valid = x[3::4,:]\n",
    "traintarget = t[0::2,:]\n",
    "testtarget = t[1::4,:]\n",
    "validtarget = t[3::4,:]\n",
    "\n",
    "# Plot the data\n",
    "pl.plot(x,t,'o')\n",
    "pl.xlabel('x')\n",
    "pl.ylabel('t')\n",
    "\n",
    "# Perform basic training with a small MLP\n",
    "import mlp\n",
    "net = mlp.mlp(train,traintarget,3,outtype='linear')\n",
    "net.mlptrain(train,traintarget,0.25,101)\n",
    "\n",
    "# Use early stopping\n",
    "net.earlystopping(train,traintarget,valid,validtarget,0.25)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Iris data set\n",
    "* [Iris Data set](https://archive.ics.uci.edu/ml/datasets/Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36142626  0.33135215 -0.7508489  -0.76741803  0.        ]\n",
      " [-0.45867099 -0.04011887 -0.7508489  -0.76741803  0.        ]\n",
      " [-0.55591572  0.10846954 -0.78268251 -0.76741803  0.        ]\n",
      " [-0.60453809  0.03417533 -0.71901528 -0.76741803  0.        ]\n",
      " [-0.41004862  0.40564636 -0.7508489  -0.76741803  0.        ]]\n",
      "1\n",
      "Iteration:  0  Error:  27.85876371042035\n",
      "2\n",
      "Iteration:  0  Error:  0.8588027183203476\n",
      "3\n",
      "Iteration:  0  Error:  0.8087335777800588\n",
      "4\n",
      "Iteration:  0  Error:  0.7804345320771774\n",
      "5\n",
      "Iteration:  0  Error:  0.7565409228767828\n",
      "6\n",
      "Iteration:  0  Error:  0.7332850016967905\n",
      "Stopped 0.5200484099764903 0.48591244121928984 0.47552591774260605\n",
      "Confusion matrix is:\n",
      "[[12.  0.  0.]\n",
      " [ 0. 12.  1.]\n",
      " [ 0.  0. 12.]]\n",
      "Percentage Correct:  97.2972972972973\n"
     ]
    }
   ],
   "source": [
    "def preprocessIris(infile,outfile):\n",
    "\n",
    "    stext1 = 'Iris-setosa'\n",
    "    stext2 = 'Iris-versicolor'\n",
    "    stext3 = 'Iris-virginica'\n",
    "    rtext1 = '0'\n",
    "    rtext2 = '1'\n",
    "    rtext3 = '2'\n",
    "\n",
    "    fid = open(infile,\"r\")\n",
    "    oid = open(outfile,\"w\")\n",
    "\n",
    "    for s in fid:\n",
    "        if s.find(stext1)>-1:\n",
    "            oid.write(s.replace(stext1, rtext1))\n",
    "        elif s.find(stext2)>-1:\n",
    "            oid.write(s.replace(stext2, rtext2))\n",
    "        elif s.find(stext3)>-1:\n",
    "            oid.write(s.replace(stext3, rtext3))\n",
    "    fid.close()\n",
    "    oid.close()\n",
    "\n",
    "iris = np.loadtxt('iris_proc.data',delimiter=',')\n",
    "iris[:,:4] = iris[:,:4]-iris[:,:4].mean(axis=0)\n",
    "imax = np.concatenate((iris.max(axis=0)*np.ones((1,5)),np.abs(iris.min(axis=0)*np.ones((1,5)))),axis=0).max(axis=0)\n",
    "iris[:,:4] = iris[:,:4]/imax[:4]\n",
    "print(iris[0:5,:])\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "target = np.zeros((np.shape(iris)[0],3));\n",
    "indices = np.where(iris[:,4]==0) \n",
    "target[indices,0] = 1\n",
    "indices = np.where(iris[:,4]==1)\n",
    "target[indices,1] = 1\n",
    "indices = np.where(iris[:,4]==2)\n",
    "target[indices,2] = 1\n",
    "\n",
    "# Randomly order the data\n",
    "order = list(range(np.shape(iris)[0])) ## python 3\n",
    "\n",
    "np.random.shuffle(order)\n",
    "iris = iris[order,:]\n",
    "target = target[order,:]\n",
    "\n",
    "train = iris[::2,0:4]\n",
    "traint = target[::2]\n",
    "valid = iris[1::4,0:4]\n",
    "validt = target[1::4]\n",
    "test = iris[3::4,0:4]\n",
    "testt = target[3::4]\n",
    "\n",
    "#print train.max(axis=0), train.min(axis=0)\n",
    "\n",
    "# Train the network\n",
    "import mlp\n",
    "net = mlp.mlp(train,traint,5,outtype='logistic')\n",
    "net.earlystopping(train,traint,valid,validt,0.1)\n",
    "net.confmat(test,testt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 1\n",
      "1\n",
      "Iteration:  0  Error:  93.50345094775088\n",
      "2\n",
      "Iteration:  0  Error:  87.72037197671762\n",
      "3\n",
      "Iteration:  0  Error:  84.3637449121243\n",
      "4\n",
      "Iteration:  0  Error:  81.99595899635365\n",
      "5\n",
      "Iteration:  0  Error:  80.90650512770571\n",
      "6\n",
      "Iteration:  0  Error:  80.36903547074485\n",
      "7\n",
      "Iteration:  0  Error:  80.05671426365132\n",
      "8\n",
      "Iteration:  0  Error:  79.84834145706871\n",
      "9\n",
      "Iteration:  0  Error:  79.69563323834407\n",
      "10\n",
      "Iteration:  0  Error:  79.57441443848222\n",
      "11\n",
      "Iteration:  0  Error:  79.46993247427072\n",
      "12\n",
      "Iteration:  0  Error:  79.37303388543086\n",
      "13\n",
      "Iteration:  0  Error:  79.27721774784663\n",
      "14\n",
      "Iteration:  0  Error:  79.17703483201717\n",
      "15\n",
      "Iteration:  0  Error:  79.06690063433575\n",
      "16\n",
      "Iteration:  0  Error:  78.94068735356247\n",
      "17\n",
      "Iteration:  0  Error:  78.79410375103923\n",
      "18\n",
      "Iteration:  0  Error:  78.62379683281287\n",
      "19\n",
      "Iteration:  0  Error:  78.41349623046695\n",
      "Stopped 82.79436172810469 82.62874597616613 82.60477340130558\n",
      "Confusion matrix is:\n",
      "[[15.  0.  2.  3.  0.  8.  0.  0.  0.  0.]\n",
      " [ 0. 27.  9.  4. 21.  3. 17. 22.  8. 19.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  1.  5.  9.  7.  9.  3.  2.  2.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Percentage Correct:  25.5\n",
      "----- 2\n",
      "1\n",
      "Iteration:  0  Error:  91.31230716670908\n",
      "2\n",
      "Iteration:  0  Error:  86.82705006124746\n",
      "3\n",
      "Iteration:  0  Error:  82.58360146042332\n",
      "4\n",
      "Iteration:  0  Error:  78.28608818003069\n",
      "5\n",
      "Iteration:  0  Error:  74.67374734492375\n",
      "6\n",
      "Iteration:  0  Error:  71.42985027440125\n",
      "7\n",
      "Iteration:  0  Error:  68.53218265749801\n",
      "8\n",
      "Iteration:  0  Error:  65.70613485899916\n",
      "9\n",
      "Iteration:  0  Error:  63.34032233606375\n",
      "10\n",
      "Iteration:  0  Error:  61.53024680510222\n",
      "11\n",
      "Iteration:  0  Error:  60.04936169056043\n",
      "12\n",
      "Iteration:  0  Error:  58.75906352965477\n",
      "13\n",
      "Iteration:  0  Error:  57.59498696677018\n",
      "14\n",
      "Iteration:  0  Error:  56.523760035387276\n",
      "15\n",
      "Iteration:  0  Error:  55.49204191205198\n",
      "16\n",
      "Iteration:  0  Error:  54.46375192779306\n",
      "17\n",
      "Iteration:  0  Error:  53.43066217096275\n",
      "18\n",
      "Iteration:  0  Error:  52.42994447364381\n",
      "19\n",
      "Iteration:  0  Error:  51.5600862283865\n",
      "20\n",
      "Iteration:  0  Error:  50.83237207207675\n",
      "21\n",
      "Iteration:  0  Error:  50.17263054048831\n",
      "Stopped 70.92805522531384 70.82440214418533 70.7583502165412\n",
      "Confusion matrix is:\n",
      "[[16.  0.  7.  2.  2.  5.  0.  0.  0.  1.]\n",
      " [ 0. 28.  0.  0.  0.  0.  0.  1.  2.  2.]\n",
      " [ 0.  0.  1.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  3. 10.  0. 11.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  4.  2.  2.  1.  4.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0. 11.  0. 16. 19.  0. 11.]\n",
      " [ 0.  0.  3.  2.  0.  2.  0.  1.  1.  0.]\n",
      " [ 0.  0.  0.  1. 11.  0.  1.  2.  3.  6.]]\n",
      "Percentage Correct:  42.5\n",
      "----- 5\n",
      "1\n",
      "Iteration:  0  Error:  91.90741132107524\n",
      "2\n",
      "Iteration:  0  Error:  84.52575344113112\n",
      "3\n",
      "Iteration:  0  Error:  71.97857012944569\n",
      "4\n",
      "Iteration:  0  Error:  56.30921190198384\n",
      "5\n",
      "Iteration:  0  Error:  45.34021489274716\n",
      "6\n",
      "Iteration:  0  Error:  37.3762447181638\n",
      "7\n",
      "Iteration:  0  Error:  31.803538184401752\n",
      "8\n",
      "Iteration:  0  Error:  27.86265964180926\n",
      "9\n",
      "Iteration:  0  Error:  24.44295027268778\n",
      "10\n",
      "Iteration:  0  Error:  21.53781221493294\n",
      "11\n",
      "Iteration:  0  Error:  19.558312633398472\n",
      "12\n",
      "Iteration:  0  Error:  17.76816178259464\n",
      "13\n",
      "Iteration:  0  Error:  15.867076495844987\n",
      "14\n",
      "Iteration:  0  Error:  14.349932974255383\n",
      "15\n",
      "Iteration:  0  Error:  13.594411274520773\n",
      "16\n",
      "Iteration:  0  Error:  13.217805935135864\n",
      "Stopped 45.06513578966635 44.84691241941947 44.82092047063506\n",
      "Confusion matrix is:\n",
      "[[14.  0.  2.  1.  0.  3.  0.  0.  0.  0.]\n",
      " [ 0. 27.  3.  1.  0.  0.  0.  1.  1.  1.]\n",
      " [ 1.  0.  5.  5.  0.  3.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  7.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  2.  0. 21.  3.  6.  0.  3.  6.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  1. 12.  0.  2.  0.]\n",
      " [ 1.  0.  2.  2.  1.  1.  1. 20.  0.  5.]\n",
      " [ 0.  0.  0.  0.  0.  8.  0.  0.  4.  0.]\n",
      " [ 0.  0.  0.  0.  5.  1.  1.  3.  0.  9.]]\n",
      "Percentage Correct:  59.5\n",
      "----- 10\n",
      "1\n",
      "Iteration:  0  Error:  90.37954591797723\n",
      "2\n",
      "Iteration:  0  Error:  81.7998678618191\n",
      "3\n",
      "Iteration:  0  Error:  62.97120258699593\n",
      "4\n",
      "Iteration:  0  Error:  45.025031274502986\n",
      "5\n",
      "Iteration:  0  Error:  33.50456395760865\n",
      "6\n",
      "Iteration:  0  Error:  26.818332535300335\n",
      "7\n",
      "Iteration:  0  Error:  22.327297567861194\n",
      "8\n",
      "Iteration:  0  Error:  19.198277441417282\n",
      "9\n",
      "Iteration:  0  Error:  16.743092400915355\n",
      "10\n",
      "Iteration:  0  Error:  13.233340741833711\n",
      "11\n",
      "Iteration:  0  Error:  10.878871531542078\n",
      "12\n",
      "Iteration:  0  Error:  9.934592869721657\n",
      "13\n",
      "Iteration:  0  Error:  9.346293092632708\n",
      "14\n",
      "Iteration:  0  Error:  8.899692479130078\n",
      "15\n",
      "Iteration:  0  Error:  8.504943246928146\n",
      "16\n",
      "Iteration:  0  Error:  8.100279303463523\n",
      "17\n",
      "Iteration:  0  Error:  7.626982259460561\n",
      "18\n",
      "Iteration:  0  Error:  6.9609361912438406\n",
      "19\n",
      "Iteration:  0  Error:  5.885195399904973\n",
      "20\n",
      "Iteration:  0  Error:  4.328664481510707\n",
      "21\n",
      "Iteration:  0  Error:  3.0669389437438044\n",
      "22\n",
      "Iteration:  0  Error:  2.4382627887905466\n",
      "23\n",
      "Iteration:  0  Error:  2.07969527940988\n",
      "24\n",
      "Iteration:  0  Error:  1.835324971723452\n",
      "25\n",
      "Iteration:  0  Error:  1.6559173770199433\n",
      "26\n",
      "Iteration:  0  Error:  1.5156730349314973\n",
      "27\n",
      "Iteration:  0  Error:  1.4017927593068646\n",
      "28\n",
      "Iteration:  0  Error:  1.3097172697184971\n",
      "29\n",
      "Iteration:  0  Error:  1.235842151903839\n",
      "Stopped 37.97445556555277 37.94713293165062 37.93937959887576\n",
      "Confusion matrix is:\n",
      "[[14.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 28.  0.  0.  0.  0.  0.  1.  1.  0.]\n",
      " [ 2.  0. 11.  3.  0.  0.  1.  0.  1.  0.]\n",
      " [ 0.  0.  2. 12.  0.  7.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1. 20.  5.  7.  3.  0.  6.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  2. 11.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  1.  0. 15.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  4.  0.  0.  7.  1.]\n",
      " [ 0.  0.  0.  0.  8.  0.  1.  5.  1. 14.]]\n",
      "Percentage Correct:  66.5\n",
      "----- 20\n",
      "1\n",
      "Iteration:  0  Error:  90.85549016597358\n",
      "2\n",
      "Iteration:  0  Error:  79.88779181604491\n",
      "3\n",
      "Iteration:  0  Error:  54.084256646387\n",
      "4\n",
      "Iteration:  0  Error:  35.541504571546085\n",
      "5\n",
      "Iteration:  0  Error:  26.627175790861422\n",
      "6\n",
      "Iteration:  0  Error:  21.80238903847482\n",
      "7\n",
      "Iteration:  0  Error:  18.68064714476875\n",
      "8\n",
      "Iteration:  0  Error:  15.195345396076963\n",
      "9\n",
      "Iteration:  0  Error:  11.107768948891128\n",
      "10\n",
      "Iteration:  0  Error:  9.728788605762254\n",
      "11\n",
      "Iteration:  0  Error:  8.977134453736515\n",
      "12\n",
      "Iteration:  0  Error:  8.437374665241805\n",
      "13\n",
      "Iteration:  0  Error:  7.938252950852255\n",
      "14\n",
      "Iteration:  0  Error:  7.342558504390125\n",
      "15\n",
      "Iteration:  0  Error:  6.394191116942074\n",
      "16\n",
      "Iteration:  0  Error:  4.401202914758112\n",
      "17\n",
      "Iteration:  0  Error:  2.7817190085197256\n",
      "18\n",
      "Iteration:  0  Error:  2.7524599548032636\n",
      "Stopped 37.53671979117725 37.30682683669154 36.95346626067327\n",
      "Confusion matrix is:\n",
      "[[15.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 28.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  0. 13.  1.  0.  1.  1.  0.  1.  0.]\n",
      " [ 0.  0.  0. 13.  0. 11.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. 23.  5.  8.  0.  0.  6.]\n",
      " [ 0.  0.  0.  0.  0.  2.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 11.  0.  0.  0.]\n",
      " [ 0.  0.  2.  2.  0.  1.  0. 20.  0.  6.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  8.  0.]\n",
      " [ 0.  0.  0.  0.  5.  0.  0.  4.  1.  9.]]\n",
      "Percentage Correct:  71.0\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset in \n",
    "import pickle, gzip\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz','rb')\n",
    "tset, vset, teset = pickle.load(f, encoding='iso-8859-1')\n",
    "f.close()\n",
    "\n",
    "nread = 200\n",
    "# Just use the first few images\n",
    "train_in = tset[0][:nread,:]\n",
    "\n",
    "# This is a little bit of work -- 1 of N encoding\n",
    "# Make sure you understand how it does it\n",
    "train_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    train_tgt[i,tset[1][i]] = 1\n",
    "\n",
    "test_in = teset[0][:nread,:]\n",
    "test_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    test_tgt[i,teset[1][i]] = 1\n",
    "\n",
    "# We will need the validation set\n",
    "valid_in = vset[0][:nread,:]\n",
    "valid_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    valid_tgt[i,vset[1][i]] = 1\n",
    "\n",
    "for i in [1,2,5,10,20]:  \n",
    "    print(\"----- \"+str(i))  \n",
    "    net = mlp.mlp(train_in,train_tgt,i,outtype='softmax')\n",
    "    net.earlystopping(train_in,train_tgt,valid_in,valid_tgt,0.1)\n",
    "    net.confmat(test_in,test_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
