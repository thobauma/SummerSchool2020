{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A python implementation for the MLP\n",
    "MLP code based on [Marsland (2014)](https://seat.massey.ac.nz/personal/s.r.marsland/MLbook.html)\n",
    "\n",
    "Contains:\n",
    "* 1. a perceptron class called **pcn**\n",
    "* 2. a Multi-layer perceptron class called **mlp**\n",
    "* 3. a test-case of the pcn\n",
    "* 4. a test-case of mlp classification\n",
    "* 5. an analytical testcase for mlp regression\n",
    "* 6. classification with the Iris data set\n",
    "* 7. classification with the MNIST data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron class (PCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class pcn:\n",
    "    \"\"\" A basic Perceptron\"\"\"\n",
    "    def __init__(self,inputs,targets):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        if np.ndim(inputs)>1:\n",
    "            self.nIn = np.shape(inputs)[1]\n",
    "        else: \n",
    "            self.nIn = 1\n",
    "\n",
    "        if np.ndim(targets)>1:\n",
    "            self.nOut = np.shape(targets)[1]\n",
    "        else:\n",
    "            self.nOut = 1\n",
    "\n",
    "        self.nData = np.shape(inputs)[0]\n",
    "\n",
    "        # Initialise network\n",
    "        self.weights = np.random.rand(self.nIn+1,self.nOut)*0.1-0.05\n",
    "\n",
    "    def pcntrain(self,inputs,targets,eta,nIterations):\n",
    "        \"\"\" Train the thing \"\"\"\t\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)\n",
    "        # Training\n",
    "        change = range(self.nData)\n",
    "\n",
    "        for n in range(nIterations):\n",
    "            self.activations = self.pcnfwd(inputs);\n",
    "            self.weights -= eta*np.dot(np.transpose(inputs),self.activations-targets)\n",
    "            \n",
    "            #Randomise order of inputs\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "\n",
    "        #return self.weights\n",
    "\n",
    "    def pcnfwd(self,inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "        # Compute activations\n",
    "        activations =  np.dot(inputs,self.weights)\n",
    "\n",
    "        # Threshold the activations\n",
    "        return np.where(activations>0,1,0)\n",
    "\n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.nData,1))),axis=1)\n",
    "\n",
    "        outputs = np.dot(inputs,self.weights)\n",
    "\n",
    "        nClasses = np.shape(targets)[1]\n",
    "\n",
    "        if nClasses==1:\n",
    "            nClasses = 2\n",
    "            outputs = np.where(outputs>0,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nClasses,nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "\n",
    "        print(cm)\n",
    "        print(np.trace(cm)/np.sum(cm))\n",
    "\n",
    "def logic():\n",
    "    import pcn\n",
    "    \"\"\" Run AND and XOR logic functions\"\"\"\n",
    "\n",
    "    a = np.array([[0,0,0],[0,1,0],[1,0,0],[1,1,1]])\n",
    "    b = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "\n",
    "    p = pcn.pcn(a[:,0:2],a[:,2:])\n",
    "    p.pcntrain(a[:,0:2],a[:,2:],0.25,10)\n",
    "    p.confmat(a[:,0:2],a[:,2:])\n",
    "\n",
    "    q = pcn.pcn(b[:,0:2],b[:,2:])\n",
    "    q.pcntrain(b[:,0:2],b[:,2:],0.25,10)\n",
    "    q.confmat(b[:,0:2],b[:,2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-layer Perceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    \"\"\" A Multi-Layer Perceptron\"\"\"\n",
    "    \n",
    "    def __init__(self,inputs,targets,nhidden,beta=1,momentum=0.9,outtype='logistic'):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        # Set up network size\n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nhidden = nhidden\n",
    "\n",
    "        self.beta = beta\n",
    "        self.momentum = momentum\n",
    "        self.outtype = outtype\n",
    "    \n",
    "        # Initialise network\n",
    "        self.weights1 = (np.random.rand(self.nin+1,self.nhidden)-0.5)*2/np.sqrt(self.nin)\n",
    "        self.weights2 = (np.random.rand(self.nhidden+1,self.nout)-0.5)*2/np.sqrt(self.nhidden)\n",
    "\n",
    "    def earlystopping(self,inputs,targets,valid,validtargets,eta,niterations=100):\n",
    "    \n",
    "        valid = np.concatenate((valid,-np.ones((np.shape(valid)[0],1))),axis=1)\n",
    "        \n",
    "        old_val_error1 = 100002\n",
    "        old_val_error2 = 100001\n",
    "        new_val_error = 100000\n",
    "        \n",
    "        count = 0\n",
    "        while (((old_val_error1 - new_val_error) > 0.001) or ((old_val_error2 - old_val_error1)>0.001)):\n",
    "            count+=1\n",
    "            print(count)\n",
    "            self.mlptrain(inputs,targets,eta,niterations)\n",
    "            old_val_error2 = old_val_error1\n",
    "            old_val_error1 = new_val_error\n",
    "            validout = self.mlpfwd(valid)\n",
    "            new_val_error = 0.5*np.sum((validtargets-validout)**2)\n",
    "            \n",
    "        print(\"Stopped\", new_val_error,old_val_error1, old_val_error2)\n",
    "        return new_val_error\n",
    "    \n",
    "    def mlptrain(self,inputs,targets,eta,niterations):\n",
    "        \"\"\" Train the thing \"\"\"    \n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((self.ndata,1))),axis=1)\n",
    "        change = range(self.ndata)\n",
    "    \n",
    "        updatew1 = np.zeros((np.shape(self.weights1)))\n",
    "        updatew2 = np.zeros((np.shape(self.weights2)))\n",
    "            \n",
    "        for n in range(niterations):\n",
    "    \n",
    "            self.outputs = self.mlpfwd(inputs)\n",
    "\n",
    "            error = 0.5*np.sum((self.outputs-targets)**2)\n",
    "            if (np.mod(n,100)==0):\n",
    "                print(\"Iteration: \",n, \" Error: \",error)    \n",
    "\n",
    "            # Different types of output neurons\n",
    "            if self.outtype == 'linear':\n",
    "            \tdeltao = (self.outputs-targets)/self.ndata\n",
    "            elif self.outtype == 'logistic':\n",
    "            \tdeltao = self.beta*(self.outputs-targets)*self.outputs*(1.0-self.outputs)\n",
    "            elif self.outtype == 'softmax':\n",
    "                deltao = (self.outputs-targets)*(self.outputs*(-self.outputs)+self.outputs)/self.ndata \n",
    "            else:\n",
    "            \tprint(\"error\")\n",
    "            \n",
    "            deltah = self.hidden*self.beta*(1.0-self.hidden)*(np.dot(deltao,np.transpose(self.weights2)))\n",
    "                      \n",
    "            updatew1 = eta*(np.dot(np.transpose(inputs),deltah[:,:-1])) + self.momentum*updatew1\n",
    "            updatew2 = eta*(np.dot(np.transpose(self.hidden),deltao)) + self.momentum*updatew2\n",
    "            self.weights1 -= updatew1\n",
    "            self.weights2 -= updatew2\n",
    "                \n",
    "            # Randomise order of inputs (not necessary for matrix-based calculation)\n",
    "            #np.random.shuffle(change)\n",
    "            #inputs = inputs[change,:]\n",
    "            #targets = targets[change,:]\n",
    "            \n",
    "    def mlpfwd(self,inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "\n",
    "        self.hidden = np.dot(inputs,self.weights1);\n",
    "        self.hidden = 1.0/(1.0+np.exp(-self.beta*self.hidden))\n",
    "        self.hidden = np.concatenate((self.hidden,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "\n",
    "        outputs = np.dot(self.hidden,self.weights2);\n",
    "\n",
    "        # Different types of output neurons\n",
    "        if self.outtype == 'linear':\n",
    "        \treturn outputs\n",
    "        elif self.outtype == 'logistic':\n",
    "            return 1.0/(1.0+np.exp(-self.beta*outputs))\n",
    "        elif self.outtype == 'softmax':\n",
    "            normalisers = np.sum(np.exp(outputs),axis=1)*np.ones((1,np.shape(outputs)[0]))\n",
    "            return np.transpose(np.transpose(np.exp(outputs))/normalisers)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the inputs that match the bias node\n",
    "        inputs = np.concatenate((inputs,-np.ones((np.shape(inputs)[0],1))),axis=1)\n",
    "        outputs = self.mlpfwd(inputs)\n",
    "        \n",
    "        nclasses = np.shape(targets)[1]\n",
    "\n",
    "        if nclasses==1:\n",
    "            nclasses = 2\n",
    "            outputs = np.where(outputs>0.5,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nclasses,nclasses))\n",
    "        for i in range(nclasses):\n",
    "            for j in range(nclasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "\n",
    "        print(\"Confusion matrix is:\")\n",
    "        print(cm)\n",
    "        print(\"Percentage Correct: \",np.trace(cm)/np.sum(cm)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the perceptron with the simple OR data-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 3.]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import pcn\n",
    "\n",
    "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "targets = np.array([[0],[1],[1],[1]])\n",
    "p = pcn.pcn(inputs,targets)\n",
    "p.pcntrain(inputs,targets,0.25,6)\n",
    "p.confmat(inputs,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the MLP with logical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  0.5650846121531008\n",
      "Iteration:  100  Error:  0.023658531239741674\n",
      "Iteration:  200  Error:  0.005422733701057971\n",
      "Iteration:  300  Error:  0.0029868097705622264\n",
      "Iteration:  400  Error:  0.0020365264975437947\n",
      "Iteration:  500  Error:  0.0015357191384466683\n",
      "Iteration:  600  Error:  0.0012282828346544747\n",
      "Iteration:  700  Error:  0.0010210893882065413\n",
      "Iteration:  800  Error:  0.0008723407803547317\n",
      "Iteration:  900  Error:  0.0007605549488482893\n",
      "Iteration:  1000  Error:  0.0006735868073282335\n",
      "Confusion matrix is:\n",
      "[[3. 0.]\n",
      " [0. 1.]]\n",
      "Percentage Correct:  100.0\n",
      "Iteration:  0  Error:  0.4999118377192949\n",
      "Iteration:  100  Error:  0.4726711872241352\n",
      "Iteration:  200  Error:  0.05108673715904432\n",
      "Iteration:  300  Error:  0.009111685609726014\n",
      "Iteration:  400  Error:  0.005000292637390241\n",
      "Iteration:  500  Error:  0.003420038596709003\n",
      "Iteration:  600  Error:  0.002588509610086325\n",
      "Iteration:  700  Error:  0.0020773746984668606\n",
      "Iteration:  800  Error:  0.001732178213335091\n",
      "Iteration:  900  Error:  0.001483793371193471\n",
      "Iteration:  1000  Error:  0.0012967153071742534\n",
      "Iteration:  1100  Error:  0.0011508637024989004\n",
      "Iteration:  1200  Error:  0.0010340399443635768\n",
      "Iteration:  1300  Error:  0.0009384119805966542\n",
      "Iteration:  1400  Error:  0.00085872439239463\n",
      "Iteration:  1500  Error:  0.0007913212324773733\n",
      "Iteration:  1600  Error:  0.0007335816836981276\n",
      "Iteration:  1700  Error:  0.0006835786166040927\n",
      "Iteration:  1800  Error:  0.0006398637649580536\n",
      "Iteration:  1900  Error:  0.0006013279762033969\n",
      "Iteration:  2000  Error:  0.0005671076399300556\n",
      "Iteration:  2100  Error:  0.0005365204380587878\n",
      "Iteration:  2200  Error:  0.0005090202391848847\n",
      "Iteration:  2300  Error:  0.00048416480327512126\n",
      "Iteration:  2400  Error:  0.0004615922480244335\n",
      "Iteration:  2500  Error:  0.00044100362633875715\n",
      "Iteration:  2600  Error:  0.00042214984215694946\n",
      "Iteration:  2700  Error:  0.000404821695745104\n",
      "Iteration:  2800  Error:  0.00038884221954316303\n",
      "Iteration:  2900  Error:  0.000374060712990473\n",
      "Iteration:  3000  Error:  0.00036034805302332637\n",
      "Iteration:  3100  Error:  0.00034759297323993225\n",
      "Iteration:  3200  Error:  0.00033569908629691727\n",
      "Iteration:  3300  Error:  0.0003245824820873996\n",
      "Iteration:  3400  Error:  0.00031416977598935615\n",
      "Iteration:  3500  Error:  0.00030439651186842093\n",
      "Iteration:  3600  Error:  0.000295205846893895\n",
      "Iteration:  3700  Error:  0.00028654746186472394\n",
      "Iteration:  3800  Error:  0.0002783766532314931\n",
      "Iteration:  3900  Error:  0.00027065357245896585\n",
      "Iteration:  4000  Error:  0.0002633425855968867\n",
      "Iteration:  4100  Error:  0.00025641173148611713\n",
      "Iteration:  4200  Error:  0.00024983226133791617\n",
      "Iteration:  4300  Error:  0.00024357824578997455\n",
      "Iteration:  4400  Error:  0.00023762623818829158\n",
      "Iteration:  4500  Error:  0.0002319549849365405\n",
      "Iteration:  4600  Error:  0.00022654517541933792\n",
      "Iteration:  4700  Error:  0.00022137922533790668\n",
      "Iteration:  4800  Error:  0.00021644108836847838\n",
      "Iteration:  4900  Error:  0.00021171609192015397\n",
      "Iteration:  5000  Error:  0.00020719079347320733\n",
      "Confusion matrix is:\n",
      "[[2. 0.]\n",
      " [0. 2.]]\n",
      "Percentage Correct:  100.0\n"
     ]
    }
   ],
   "source": [
    "import mlp\n",
    "\n",
    "anddata = np.array([[0,0,0],[0,1,0],[1,0,0],[1,1,1]])\n",
    "xordata = np.array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "\n",
    "p = mlp.mlp(anddata[:,0:2],anddata[:,2:3],2)\n",
    "p.mlptrain(anddata[:,0:2],anddata[:,2:3],0.25,1001)\n",
    "p.confmat(anddata[:,0:2],anddata[:,2:3])\n",
    "\n",
    "q = mlp.mlp(xordata[:,0:2],xordata[:,2:3],2,outtype='logistic')\n",
    "q.mlptrain(xordata[:,0:2],xordata[:,2:3],0.25,5001)\n",
    "q.confmat(xordata[:,0:2],xordata[:,2:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The first thing that we can do is check that this MLP can indeed learn the logic functions, especially the XOR. \n",
    "\n",
    "* There are a few things to notice about this. \n",
    "\n",
    "\n",
    "* One is that it does work, producing the correct answers, but the other is that even for the AND we need significantly more iterations than we did for the Perceptron. \n",
    "\n",
    "* So the benefits of a more complex network come at a cost, because it takes substantially more computational time to fit those weights to solve the problem, even for linear examples. \n",
    "\n",
    "* Sometimes, even 5000 iterations are not enough for the XOR function, and more have to be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A simple regression problem\n",
    "\n",
    "* The regression problem we will look at is a very simple one. \n",
    "\n",
    "* We will take a set of samples generated by a simple mathematical function, and try to learn the generating function (that describes how the data was made) so that we can find the values of any inputs, not just the ones we have training data for.\n",
    "\n",
    "* The function that we will use is a very simple one, just a bit of a sine wave. \n",
    "\n",
    "* Before getting started, we need to normalize the data separate the data into training, testing, validation sets. \n",
    "\n",
    "* For this example there are only 40 data points \n",
    "\n",
    "* We use half of them as the training set, although that isn’t very many and might not be enough for the algorithm to learn effectively. \n",
    "\n",
    "* We can split the data in the ratio 50:25:25 by using the odd-numbered elements as training data, the even-numbered ones that do not divide by 4 for testing, and the rest for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Error:  9.99475099549847\n",
      "Iteration:  100  Error:  6.775143970984858\n",
      "1\n",
      "Iteration:  0  Error:  6.770401779958986\n",
      "2\n",
      "Iteration:  0  Error:  6.025673703809727\n",
      "3\n",
      "Iteration:  0  Error:  4.338481574423242\n",
      "4\n",
      "Iteration:  0  Error:  1.769274089088693\n",
      "5\n",
      "Iteration:  0  Error:  1.1195345676746595\n",
      "6\n",
      "Iteration:  0  Error:  1.073279193962202\n",
      "Stopped 0.7422629440378776 0.7224698509354552 0.6974443193165912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8ef856ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the data\n",
    "import pylab as pl\n",
    "\n",
    "x = np.linspace(0,1,40).reshape((40,1))\n",
    "t = np.sin(2*np.pi*x) + np.cos(4*np.pi*x) + np.random.randn(40).reshape((40,1))*0.2\n",
    "x = (x-0.5)*2\n",
    "\n",
    "# Split into training, testing, and validation sets\n",
    "train = x[0::2,:]\n",
    "test = x[1::4,:]\n",
    "valid = x[3::4,:]\n",
    "traintarget = t[0::2,:]\n",
    "testtarget = t[1::4,:]\n",
    "validtarget = t[3::4,:]\n",
    "\n",
    "# Plot the data\n",
    "pl.plot(x,t,'o')\n",
    "pl.xlabel('x')\n",
    "pl.ylabel('t')\n",
    "\n",
    "# Perform basic training with a small MLP\n",
    "import mlp\n",
    "net = mlp.mlp(train,traintarget,3,outtype='linear')\n",
    "net.mlptrain(train,traintarget,0.25,101)\n",
    "\n",
    "# Use early stopping\n",
    "net.earlystopping(train,traintarget,valid,validtarget,0.25)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Iris data set\n",
    "* [Iris Data set](https://archive.ics.uci.edu/ml/datasets/Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36142626  0.33135215 -0.7508489  -0.76741803  0.        ]\n",
      " [-0.45867099 -0.04011887 -0.7508489  -0.76741803  0.        ]\n",
      " [-0.55591572  0.10846954 -0.78268251 -0.76741803  0.        ]\n",
      " [-0.60453809  0.03417533 -0.71901528 -0.76741803  0.        ]\n",
      " [-0.41004862  0.40564636 -0.7508489  -0.76741803  0.        ]]\n",
      "1\n",
      "Iteration:  0  Error:  27.730721113279362\n",
      "2\n",
      "Iteration:  0  Error:  0.7549952946242144\n",
      "3\n",
      "Iteration:  0  Error:  0.41331291231945144\n",
      "4\n",
      "Iteration:  0  Error:  0.25165082761263663\n",
      "5\n",
      "Iteration:  0  Error:  0.16455343168982925\n",
      "6\n",
      "Iteration:  0  Error:  0.11472698081610233\n",
      "7\n",
      "Iteration:  0  Error:  0.0845441493435886\n",
      "8\n",
      "Iteration:  0  Error:  0.06516394241834236\n",
      "Stopped 0.001689569061368463 0.0022313273668441535 0.003151128169824274\n",
      "Confusion matrix is:\n",
      "[[ 8.  0.  0.]\n",
      " [ 0. 10.  0.]\n",
      " [ 0.  2. 17.]]\n",
      "Percentage Correct:  94.5945945945946\n"
     ]
    }
   ],
   "source": [
    "def preprocessIris(infile,outfile):\n",
    "\n",
    "    stext1 = 'Iris-setosa'\n",
    "    stext2 = 'Iris-versicolor'\n",
    "    stext3 = 'Iris-virginica'\n",
    "    rtext1 = '0'\n",
    "    rtext2 = '1'\n",
    "    rtext3 = '2'\n",
    "\n",
    "    fid = open(infile,\"r\")\n",
    "    oid = open(outfile,\"w\")\n",
    "\n",
    "    for s in fid:\n",
    "        if s.find(stext1)>-1:\n",
    "            oid.write(s.replace(stext1, rtext1))\n",
    "        elif s.find(stext2)>-1:\n",
    "            oid.write(s.replace(stext2, rtext2))\n",
    "        elif s.find(stext3)>-1:\n",
    "            oid.write(s.replace(stext3, rtext3))\n",
    "    fid.close()\n",
    "    oid.close()\n",
    "\n",
    "iris = np.loadtxt('iris_proc.data',delimiter=',')\n",
    "iris[:,:4] = iris[:,:4]-iris[:,:4].mean(axis=0)\n",
    "imax = np.concatenate((iris.max(axis=0)*np.ones((1,5)),np.abs(iris.min(axis=0)*np.ones((1,5)))),axis=0).max(axis=0)\n",
    "iris[:,:4] = iris[:,:4]/imax[:4]\n",
    "print(iris[0:5,:])\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "target = np.zeros((np.shape(iris)[0],3));\n",
    "indices = np.where(iris[:,4]==0) \n",
    "target[indices,0] = 1\n",
    "indices = np.where(iris[:,4]==1)\n",
    "target[indices,1] = 1\n",
    "indices = np.where(iris[:,4]==2)\n",
    "target[indices,2] = 1\n",
    "\n",
    "# Randomly order the data\n",
    "order = list(range(np.shape(iris)[0])) ## python 3\n",
    "\n",
    "np.random.shuffle(order)\n",
    "iris = iris[order,:]\n",
    "target = target[order,:]\n",
    "\n",
    "train = iris[::2,0:4]\n",
    "traint = target[::2]\n",
    "valid = iris[1::4,0:4]\n",
    "validt = target[1::4]\n",
    "test = iris[3::4,0:4]\n",
    "testt = target[3::4]\n",
    "\n",
    "#print train.max(axis=0), train.min(axis=0)\n",
    "\n",
    "# Train the network\n",
    "import mlp\n",
    "net = mlp.mlp(train,traint,5,outtype='logistic')\n",
    "net.earlystopping(train,traint,valid,validt,0.1)\n",
    "net.confmat(test,testt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 1\n",
      "1\n",
      "Iteration:  0  Error:  95.11129310575865\n",
      "2\n",
      "Iteration:  0  Error:  87.3340048840538\n",
      "3\n",
      "Iteration:  0  Error:  85.2054690433427\n",
      "4\n",
      "Iteration:  0  Error:  83.96776101430191\n",
      "5\n",
      "Iteration:  0  Error:  83.05806329090859\n",
      "6\n",
      "Iteration:  0  Error:  82.2897184202881\n",
      "7\n",
      "Iteration:  0  Error:  81.60197303002417\n",
      "8\n",
      "Iteration:  0  Error:  80.96864851593048\n",
      "9\n",
      "Iteration:  0  Error:  80.36811849406736\n",
      "10\n",
      "Iteration:  0  Error:  79.78487237276622\n",
      "11\n",
      "Iteration:  0  Error:  79.20778077825929\n",
      "12\n",
      "Iteration:  0  Error:  78.62569041574008\n",
      "13\n",
      "Iteration:  0  Error:  78.02464968556858\n",
      "14\n",
      "Iteration:  0  Error:  77.3895265225496\n",
      "15\n",
      "Iteration:  0  Error:  76.72217548119531\n",
      "16\n",
      "Iteration:  0  Error:  76.05313490005281\n",
      "17\n",
      "Iteration:  0  Error:  75.40939035292749\n",
      "18\n",
      "Iteration:  0  Error:  74.80787485075724\n",
      "19\n",
      "Iteration:  0  Error:  74.25643837854136\n",
      "Stopped 83.5887632230564 83.54817974973982 83.5295144450886\n",
      "Confusion matrix is:\n",
      "[[17.  0.  6. 11.  5. 11. 16.  2.  6.  1.]\n",
      " [ 0. 28.  2.  1. 10.  3.  0. 10.  0.  4.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0.  2.  2.  1.  2.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  3.  0.  0.  7.  1.  2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  6.  3.  8.  4.  3.  3.  3. 12.]]\n",
      "Percentage Correct:  32.0\n",
      "----- 2\n",
      "1\n",
      "Iteration:  0  Error:  94.03954211854774\n",
      "2\n",
      "Iteration:  0  Error:  88.14895691998277\n",
      "3\n",
      "Iteration:  0  Error:  84.11883959321989\n",
      "4\n",
      "Iteration:  0  Error:  79.33217110650833\n",
      "5\n",
      "Iteration:  0  Error:  74.21491883649703\n",
      "6\n",
      "Iteration:  0  Error:  69.88066342721123\n",
      "7\n",
      "Iteration:  0  Error:  66.78297964269204\n",
      "8\n",
      "Iteration:  0  Error:  64.68457087246082\n",
      "9\n",
      "Iteration:  0  Error:  63.24439384681435\n",
      "10\n",
      "Iteration:  0  Error:  62.24042883067834\n",
      "11\n",
      "Iteration:  0  Error:  61.48968260788405\n",
      "Stopped 77.29345402384813 77.25255525877196 77.22833919739327\n",
      "Confusion matrix is:\n",
      "[[16.  1. 10.  1.  1.  1. 11.  0.  2.  0.]\n",
      " [ 1. 20.  3.  0.  0.  2.  4.  0.  3.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  6.  1. 15.  0. 13.  1.  0.  3.  0.]\n",
      " [ 0.  0.  0.  0.  1.  2.  0.  3.  2.  5.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  2.  0.  8.  1.  4. 18.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0. 18.  1.  0.  3.  0. 13.]]\n",
      "Percentage Correct:  41.5\n",
      "----- 5\n",
      "1\n",
      "Iteration:  0  Error:  91.22883178175792\n",
      "2\n",
      "Iteration:  0  Error:  84.48631751332422\n",
      "3\n",
      "Iteration:  0  Error:  73.73719799323989\n",
      "4\n",
      "Iteration:  0  Error:  63.807551973236635\n",
      "5\n",
      "Iteration:  0  Error:  55.656510808594\n",
      "6\n",
      "Iteration:  0  Error:  48.41544377343408\n",
      "7\n",
      "Iteration:  0  Error:  40.57530437874438\n",
      "8\n",
      "Iteration:  0  Error:  33.05342980785862\n",
      "9\n",
      "Iteration:  0  Error:  26.56198030915173\n",
      "10\n",
      "Iteration:  0  Error:  21.591415584067352\n",
      "11\n",
      "Iteration:  0  Error:  18.365839037409167\n",
      "12\n",
      "Iteration:  0  Error:  16.25840319390459\n",
      "13\n",
      "Iteration:  0  Error:  14.521127736506626\n",
      "14\n",
      "Iteration:  0  Error:  12.908227476619805\n",
      "15\n",
      "Iteration:  0  Error:  11.902127889957772\n",
      "16\n",
      "Iteration:  0  Error:  11.211563014427878\n",
      "17\n",
      "Iteration:  0  Error:  10.706584201611255\n",
      "18\n",
      "Iteration:  0  Error:  10.322143883364909\n",
      "19\n",
      "Iteration:  0  Error:  10.021569885883707\n",
      "20\n",
      "Iteration:  0  Error:  9.763928736602708\n",
      "Stopped 43.912994414655 43.74129446125281 43.21045756464292\n",
      "Confusion matrix is:\n",
      "[[12.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 28.  1.  1.  0.  0.  0.  2.  0.  0.]\n",
      " [ 2.  0. 12.  2.  0.  1.  3.  1.  0.  0.]\n",
      " [ 0.  0.  0. 10.  0.  9.  0.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0. 18.  2.  2.  0.  0.  3.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 11.  0.  1.  0.]\n",
      " [ 2.  0.  1.  0.  5.  1.  4. 18.  0.  7.]\n",
      " [ 0.  0.  1.  2.  0.  1.  0.  0.  9.  2.]\n",
      " [ 0.  0.  0.  0.  5.  6.  0.  3.  0.  9.]]\n",
      "Percentage Correct:  63.5\n",
      "----- 10\n",
      "1\n",
      "Iteration:  0  Error:  91.25154330202986\n",
      "2\n",
      "Iteration:  0  Error:  83.28150677987344\n",
      "3\n",
      "Iteration:  0  Error:  65.96521364180565\n",
      "4\n",
      "Iteration:  0  Error:  49.126265105087384\n",
      "5\n",
      "Iteration:  0  Error:  36.61524628069745\n",
      "6\n",
      "Iteration:  0  Error:  28.004017222704995\n",
      "7\n",
      "Iteration:  0  Error:  23.2895595625476\n",
      "8\n",
      "Iteration:  0  Error:  20.508070039912504\n",
      "9\n",
      "Iteration:  0  Error:  18.617975795098552\n",
      "10\n",
      "Iteration:  0  Error:  16.916085311470056\n",
      "11\n",
      "Iteration:  0  Error:  15.06566099952168\n",
      "12\n",
      "Iteration:  0  Error:  13.487200743494775\n",
      "13\n",
      "Iteration:  0  Error:  12.48178330379628\n",
      "14\n",
      "Iteration:  0  Error:  11.559583917339609\n",
      "15\n",
      "Iteration:  0  Error:  10.768837337779793\n",
      "16\n",
      "Iteration:  0  Error:  9.964510983675485\n",
      "17\n",
      "Iteration:  0  Error:  9.067222277279333\n",
      "18\n",
      "Iteration:  0  Error:  7.960368023623034\n",
      "19\n",
      "Iteration:  0  Error:  6.523481806498209\n",
      "20\n",
      "Iteration:  0  Error:  5.052625206551822\n",
      "21\n",
      "Iteration:  0  Error:  4.140450133973344\n",
      "22\n",
      "Iteration:  0  Error:  3.4658419330885986\n",
      "23\n",
      "Iteration:  0  Error:  2.9235917269604026\n",
      "24\n",
      "Iteration:  0  Error:  2.583547710373309\n",
      "25\n",
      "Iteration:  0  Error:  2.3970712966486865\n",
      "Stopped 41.72647973774319 41.46216107520082 41.371378964208276\n",
      "Confusion matrix is:\n",
      "[[14.  0.  0.  0.  1.  2.  0.  0.  1.  0.]\n",
      " [ 0. 28.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. 12.  2.  0.  2.  6.  0.  0.  0.]\n",
      " [ 0.  0.  0.  7.  0.  2.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. 17.  5.  1.  1.  2.  5.]\n",
      " [ 0.  0.  1.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0. 11.  0.  0.  0.]\n",
      " [ 1.  0.  1.  6.  3.  2.  2. 20.  2.  5.]\n",
      " [ 0.  0.  0.  1.  0.  6.  0.  0.  5.  1.]\n",
      " [ 0.  0.  0.  0.  7.  0.  0.  3.  0. 10.]]\n",
      "Percentage Correct:  62.5\n",
      "----- 20\n",
      "1\n",
      "Iteration:  0  Error:  90.92810046585231\n",
      "2\n",
      "Iteration:  0  Error:  79.87715843125228\n",
      "3\n",
      "Iteration:  0  Error:  55.019746603120275\n",
      "4\n",
      "Iteration:  0  Error:  34.661624637807975\n",
      "5\n",
      "Iteration:  0  Error:  26.081972235527232\n",
      "6\n",
      "Iteration:  0  Error:  21.414663465906138\n",
      "7\n",
      "Iteration:  0  Error:  18.64099416894004\n",
      "8\n",
      "Iteration:  0  Error:  16.78880517645257\n",
      "9\n",
      "Iteration:  0  Error:  15.126309314683366\n",
      "10\n",
      "Iteration:  0  Error:  13.138697995217278\n",
      "11\n",
      "Iteration:  0  Error:  11.173420173385779\n",
      "12\n",
      "Iteration:  0  Error:  9.982677548504183\n",
      "13\n",
      "Iteration:  0  Error:  9.073990111067076\n",
      "14\n",
      "Iteration:  0  Error:  8.352860594877676\n",
      "15\n",
      "Iteration:  0  Error:  7.672624586513611\n",
      "16\n",
      "Iteration:  0  Error:  6.857710714265232\n",
      "17\n",
      "Iteration:  0  Error:  5.675537329563106\n",
      "18\n",
      "Iteration:  0  Error:  4.169278434473764\n",
      "Stopped 36.22937346155061 35.72570564033025 35.56426162074581\n",
      "Confusion matrix is:\n",
      "[[15.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 28.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 2.  0. 14.  2.  0.  1.  3.  0.  0.  0.]\n",
      " [ 0.  0.  0. 13.  0.  8.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0. 23.  5.  5.  0.  1.  6.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 12.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  1.  0. 21.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.  3.  0.  0.  7.  0.]\n",
      " [ 0.  0.  0.  0.  5.  1.  0.  3.  2. 13.]]\n",
      "Percentage Correct:  73.5\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset in \n",
    "import pickle, gzip\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz','rb')\n",
    "tset, vset, teset = pickle.load(f, encoding='iso-8859-1')\n",
    "f.close()\n",
    "\n",
    "nread = 200\n",
    "# Just use the first few images\n",
    "train_in = tset[0][:nread,:]\n",
    "\n",
    "# This is a little bit of work -- 1 of N encoding\n",
    "# Make sure you understand how it does it\n",
    "train_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    train_tgt[i,tset[1][i]] = 1\n",
    "\n",
    "test_in = teset[0][:nread,:]\n",
    "test_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    test_tgt[i,teset[1][i]] = 1\n",
    "\n",
    "# We will need the validation set\n",
    "valid_in = vset[0][:nread,:]\n",
    "valid_tgt = np.zeros((nread,10))\n",
    "for i in range(nread):\n",
    "    valid_tgt[i,vset[1][i]] = 1\n",
    "\n",
    "for i in [1,2,5,10,20]:  \n",
    "    print(\"----- \"+str(i))  \n",
    "    net = mlp.mlp(train_in,train_tgt,i,outtype='softmax')\n",
    "    net.earlystopping(train_in,train_tgt,valid_in,valid_tgt,0.1)\n",
    "    net.confmat(test_in,test_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
